{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transforming requirements into DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Project</th>\n",
       "      <th>Requirement</th>\n",
       "      <th>Class</th>\n",
       "      <th>Ambiguity</th>\n",
       "      <th>Ambiguity Type</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>The system shall refresh the display every 60 ...</td>\n",
       "      <td>PE</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>The application shall match the color of the s...</td>\n",
       "      <td>LF</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected the data must be readable.  On a ...</td>\n",
       "      <td>US</td>\n",
       "      <td>0</td>\n",
       "      <td>NA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>The product shall be available during normal b...</td>\n",
       "      <td>A</td>\n",
       "      <td>1</td>\n",
       "      <td>VG</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>If projected the data must be understandable. ...</td>\n",
       "      <td>US</td>\n",
       "      <td>1</td>\n",
       "      <td>VG</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  Project                                        Requirement Class Ambiguity  \\\n",
       "0       1  The system shall refresh the display every 60 ...    PE         0   \n",
       "1       1  The application shall match the color of the s...    LF         0   \n",
       "2       1  If projected the data must be readable.  On a ...    US         0   \n",
       "3       1  The product shall be available during normal b...     A         1   \n",
       "4       1  If projected the data must be understandable. ...    US         1   \n",
       "\n",
       "  Ambiguity Type  \n",
       "0             NA  \n",
       "1             NA  \n",
       "2             NA  \n",
       "3             VG  \n",
       "4             VG  "
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import arff\n",
    "import pandas as pd\n",
    "\n",
    "data = arff.load('PROMISE_exp.arff')\n",
    "\n",
    "df = pd.DataFrame(data)\n",
    "\n",
    "df.columns =['Project', 'Requirement', 'Class', 'Ambiguity', 'Ambiguity Type']\n",
    "\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Showing database balance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0.896447\n",
       "1    0.103553\n",
       "Name: Ambiguity, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['Ambiguity'].value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Feature Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "\n",
    "stemmer = SnowballStemmer(\"english\", ignore_stopwords=True)\n",
    "\n",
    "class StemmedCountVectorizer(CountVectorizer):\n",
    "    def build_analyzer(self):\n",
    "        analyzer = super(StemmedCountVectorizer, self).build_analyzer()\n",
    "        return lambda doc: ([stemmer.stem(w) for w in analyzer(doc)])\n",
    "\n",
    "stemmed_count_vect = StemmedCountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(985, 1336)\n"
     ]
    }
   ],
   "source": [
    "count_vect = CountVectorizer(stop_words='english')\n",
    "X_requirement_counts = stemmed_count_vect.fit_transform(df['Requirement'])\n",
    "print(X_requirement_counts.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "TF-IDF (Term Frequencyâ€”Inverse Document Frequency)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(985, 1336)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_requirement_tfidf = tfidf_transformer.fit_transform(X_requirement_counts)\n",
    "X_requirement_tfidf.shape\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Split Test and Train sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "train_x, test_x, train_y, test_y = train_test_split(X_requirement_tfidf, df['Ambiguity'], test_size=0.3, stratify=df['Ambiguity'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Balancing traing sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(689, 1336)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(1236, 1336)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "print(train_x.shape)\n",
    "oversample = SMOTE(sampling_strategy=1)\n",
    "train_x, train_y = oversample.fit_resample(train_x, train_y)\n",
    "train_x.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Run ML Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "y_scores = []\n",
    "\n",
    "clf_mnb = MultinomialNB().fit(train_x, train_y)\n",
    "y_score_mnb = clf_mnb.predict(test_x)\n",
    "y_scores.append(('Multinomial Naive Bayes', y_score_mnb, clf_mnb))\n",
    "\n",
    "clf_knc = KNeighborsClassifier().fit(train_x, train_y)\n",
    "y_score_knc = clf_knc.predict(test_x)\n",
    "y_scores.append(('K-Nearest Neighbor', y_score_knc, clf_knc))\n",
    "\n",
    "clf_svc = SVC().fit(train_x, train_y)\n",
    "y_score_svc = clf_svc.predict(test_x)\n",
    "y_scores.append(('Support Vector Machine', y_score_svc, clf_svc))\n",
    "\n",
    "clf_lr = LogisticRegression(random_state=0).fit(train_x, train_y)\n",
    "y_score_lr = clf_lr.predict(test_x)\n",
    "y_scores.append(('Logistic Regression', y_score_lr, clf_lr))\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Show Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Multinomial Naive Bayes\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unambiguous       0.95      0.88      0.91       265\n",
      "   Ambiguous       0.37      0.58      0.45        31\n",
      "\n",
      "    accuracy                           0.85       296\n",
      "   macro avg       0.66      0.73      0.68       296\n",
      "weighted avg       0.89      0.85      0.87       296\n",
      "\n",
      "\n",
      "K-Nearest Neighbor\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unambiguous       1.00      0.45      0.62       265\n",
      "   Ambiguous       0.18      1.00      0.30        31\n",
      "\n",
      "    accuracy                           0.51       296\n",
      "   macro avg       0.59      0.72      0.46       296\n",
      "weighted avg       0.91      0.51      0.59       296\n",
      "\n",
      "\n",
      "Support Vector Machine\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unambiguous       0.91      1.00      0.95       265\n",
      "   Ambiguous       0.83      0.16      0.27        31\n",
      "\n",
      "    accuracy                           0.91       296\n",
      "   macro avg       0.87      0.58      0.61       296\n",
      "weighted avg       0.90      0.91      0.88       296\n",
      "\n",
      "\n",
      "Logistic Regression\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      " Unambiguous       0.94      0.96      0.95       265\n",
      "   Ambiguous       0.58      0.48      0.53        31\n",
      "\n",
      "    accuracy                           0.91       296\n",
      "   macro avg       0.76      0.72      0.74       296\n",
      "weighted avg       0.90      0.91      0.91       296\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import recall_score, accuracy_score, precision_score, f1_score, plot_confusion_matrix, classification_report\n",
    "\n",
    "target_names = [\"Unambiguous\", \"Ambiguous\"]\n",
    "\n",
    "for model, y_score, clf in y_scores: \n",
    "    print(model)\n",
    "    print(classification_report(test_y, y_score, target_names=target_names))\n",
    "    print()\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "b0fa6594d8f4cbf19f97940f81e996739fb7646882a419484c72d19e05852a7e"
  },
  "kernelspec": {
   "display_name": "Python 3.9.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.3"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
